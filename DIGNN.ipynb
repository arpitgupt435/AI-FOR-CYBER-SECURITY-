{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6945e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: INSTALL DEPENDENCIES ---\n",
    "# Run this cell once to install the required libraries for Graph Neural Networks\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q pandas numpy scikit-learn\n",
    "\n",
    "# --- STEP 2: IMPORT MODULES ---\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# PyTorch Geometric (Graph Library)\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import TransformerConv, GCN2Conv\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- STEP 3: DEVICE CONFIGURATION ---\n",
    "# Automatically detects if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Setup Complete. Using Device: {device}\")\n",
    "\n",
    "# --- STEP 4: HYPERPARAMETERS (From DIGNN Paper) ---\n",
    "CONFIG = {\n",
    "    'snapshot_size': 2048,   # Paper optimal: 2048 flows per graph\n",
    "    'window_size': 10,       # Paper optimal: Sequence length of 10\n",
    "    'hidden_dim': 64,        # Dimension of hidden layers\n",
    "    'heads': 2,              # Attention heads for TransformerConv\n",
    "    'epochs': 50,            # Sufficient for convergence\n",
    "    'lr': 0.001              # Learning Rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ebe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BLOCK 3: LINE GRAPH GENERATION (Run BEFORE Block 2) ---\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_snapshots(df, feat_cols, label_col, snapshot_size):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame chunk into a list of Graph Snapshots.\n",
    "    Nodes = Network Flows.\n",
    "    Edges = Shared IP Addresses (Line Graph Methodology).\n",
    "    \"\"\"\n",
    "    # Don't print for every chunk to keep output clean\n",
    "    # print(f\"  Generating snapshots...\") \n",
    "    \n",
    "    snapshots = []\n",
    "    num_samples = len(df)\n",
    "    \n",
    "    # Iterate through the dataframe chunk in steps of 'snapshot_size'\n",
    "    for i in range(0, num_samples, snapshot_size):\n",
    "        # 1. Slice the Window\n",
    "        window = df.iloc[i : i + snapshot_size].reset_index(drop=True)\n",
    "        if len(window) < 10: continue # Skip tiny tails\n",
    "        \n",
    "        # 2. Node Features (X) & Labels (Y)\n",
    "        x = torch.tensor(window[feat_cols].values, dtype=torch.float)\n",
    "        y = torch.tensor(window[label_col].values, dtype=torch.long)\n",
    "        \n",
    "        # 3. Edge Construction (Line Graph Logic)\n",
    "        # We connect flows that share a Source IP or Destination IP.\n",
    "        \n",
    "        # Check if topology columns exist (they should, based on Block 2)\n",
    "        if 'srcip' in window.columns and 'dstip' in window.columns:\n",
    "            ip_map = {}\n",
    "            srcs = window['srcip'].values\n",
    "            dsts = window['dstip'].values\n",
    "            \n",
    "            # Map IP -> List of Flow Indices\n",
    "            for idx, (s, d) in enumerate(zip(srcs, dsts)):\n",
    "                if s not in ip_map: ip_map[s] = []\n",
    "                if d not in ip_map: ip_map[d] = []\n",
    "                ip_map[s].append(idx)\n",
    "                ip_map[d].append(idx)\n",
    "                \n",
    "            src_e, dst_e = [], []\n",
    "            \n",
    "            # Create Edges\n",
    "            for ip, nodes in ip_map.items():\n",
    "                if len(nodes) > 1:\n",
    "                    # Chain Connection: Connect 0-1, 1-2, 2-3...\n",
    "                    # This creates a path through all flows sharing the IP.\n",
    "                    # It is much more memory efficient than Fully Connected.\n",
    "                    for k in range(len(nodes)-1):\n",
    "                        u, v = nodes[k], nodes[k+1]\n",
    "                        # Undirected Graph (Add both directions)\n",
    "                        src_e.extend([u, v])\n",
    "                        dst_e.extend([v, u])\n",
    "                        \n",
    "            if src_e:\n",
    "                edge_index = torch.tensor([src_e, dst_e], dtype=torch.long)\n",
    "            else:\n",
    "                # Fallback: No shared IPs in this small window (rare)\n",
    "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        else:\n",
    "            # Fallback if topology cols missing\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "            \n",
    "        # Create PyG Data Object\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        snapshots.append(data)\n",
    "        \n",
    "    return snapshots\n",
    "\n",
    "# --- USAGE LINES ---\n",
    "# This function is usually NOT called manually. \n",
    "# It is called automatically by 'process_data_incrementally' in Block 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab107e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Parsing Feature Headers from NUSW-NB15_features.csv...\n",
      "\n",
      "Processing UNSW-NB15_1.csv...\n",
      "  Fitting Scaler on first file...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 342\n",
      "\n",
      "Processing UNSW-NB15_2.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 684\n",
      "\n",
      "Processing UNSW-NB15_3.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 1026\n",
      "\n",
      "Processing UNSW-NB15_4.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 1241\n",
      "Final Dataset Ready: 1241 snapshots.\n"
     ]
    }
   ],
   "source": [
    "# --- BLOCK 2: INCREMENTAL PROCESSING (RAM FRIENDLY) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc  # Garbage Collector\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def process_data_incrementally(file_paths, features_csv, snapshot_size):\n",
    "    \"\"\"\n",
    "    Processes UNSW-NB15 CSV files incrementally using the Paper's snapshot size.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- SETUP HEADERS ---\n",
    "    print(f\"Step 1: Parsing Feature Headers from {features_csv}...\")\n",
    "    if not os.path.exists(features_csv):\n",
    "        raise FileNotFoundError(f\"Features file not found: {features_csv}\")\n",
    "        \n",
    "    feat_df = pd.read_csv(features_csv, encoding='cp1252')\n",
    "    headers = feat_df['Name'].str.strip().str.lower().tolist()\n",
    "    \n",
    "    # Scaler for consistent normalization across files\n",
    "    scaler = MinMaxScaler()\n",
    "    is_scaler_fitted = False\n",
    "    \n",
    "    all_snapshots = [] \n",
    "    input_dim = 0      \n",
    "    \n",
    "    # --- LOOP THROUGH FILES ---\n",
    "    for fpath in file_paths:\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"Skipping missing file: {fpath}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing {fpath}...\")\n",
    "        \n",
    "        # 1. LOAD SINGLE FILE\n",
    "        df = pd.read_csv(fpath, header=None, names=headers, low_memory=False)\n",
    "        \n",
    "        # 2. HANDLE LABELS\n",
    "        if 'label' in df.columns:\n",
    "            df['label'] = pd.to_numeric(df['label'], errors='coerce').fillna(0).astype(int)\n",
    "            label_col = 'label'\n",
    "        elif 'attack_cat' in df.columns:\n",
    "            df['label'] = df['attack_cat'].apply(lambda x: 0 if str(x).strip().lower() == 'normal' else 1)\n",
    "            label_col = 'label'\n",
    "        else:\n",
    "            df.rename(columns={df.columns[-1]: 'label'}, inplace=True)\n",
    "            label_col = 'label'\n",
    "            \n",
    "        # 3. SORT (Time)\n",
    "        if 'stime' in df.columns:\n",
    "            df = df.sort_values('stime').reset_index(drop=True)\n",
    "            \n",
    "        # 4. PREPARE FEATURES\n",
    "        topo_cols = ['srcip', 'sport', 'dstip', 'dsport', 'proto']\n",
    "        cat_cols = ['proto', 'service', 'state']\n",
    "        \n",
    "        # One-Hot Encoding\n",
    "        existing_cat = [c for c in cat_cols if c in df.columns]\n",
    "        if existing_cat:\n",
    "            df = pd.get_dummies(df, columns=existing_cat, drop_first=True)\n",
    "            \n",
    "        # Select Features\n",
    "        exclude_cols = topo_cols + [label_col, 'id', 'attack_cat']\n",
    "        feat_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "        \n",
    "        # Force Numeric\n",
    "        for c in feat_cols:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df.fillna(0, inplace=True)\n",
    "        \n",
    "        # Filter to only numeric columns to avoid dtype conversion errors\n",
    "        numeric_dtypes = [np.float64, np.float32, np.int64, np.int32, np.int16, np.int8, np.uint64, np.uint32, np.uint16, np.uint8]\n",
    "        feat_cols = [c for c in feat_cols if df[c].dtype in numeric_dtypes]\n",
    "        \n",
    "        # 5. SCALE\n",
    "        if not is_scaler_fitted:\n",
    "            print(\"  Fitting Scaler on first file...\")\n",
    "            scaler.fit(df[feat_cols])\n",
    "            input_dim = len(feat_cols)\n",
    "            is_scaler_fitted = True\n",
    "        \n",
    "        # align columns\n",
    "        current_cols = [c for c in feat_cols if c in df.columns]\n",
    "        if len(current_cols) == input_dim:\n",
    "             df[current_cols] = scaler.transform(df[current_cols])\n",
    "\n",
    "        # 6. GENERATE SNAPSHOTS (Using Configured Size)\n",
    "        print(f\"  Generating snapshots (Size: {snapshot_size})...\")\n",
    "        \n",
    "        # Note: Ensure Block 3 (create_snapshots) is already run/defined before this!\n",
    "        file_snapshots = create_snapshots(df, feat_cols, label_col, snapshot_size)\n",
    "        all_snapshots.extend(file_snapshots)\n",
    "        \n",
    "        print(f\"  Done. Total snapshots so far: {len(all_snapshots)}\")\n",
    "        \n",
    "        # 7. CLEAR RAM\n",
    "        del df\n",
    "        del file_snapshots\n",
    "        gc.collect() \n",
    "        \n",
    "    return all_snapshots, input_dim\n",
    "\n",
    "# --- USAGE LINES ---\n",
    "# 1. Define File Paths\n",
    "data_files = [\n",
    "    'UNSW-NB15_1.csv',\n",
    "    'UNSW-NB15_2.csv',\n",
    "    'UNSW-NB15_3.csv',\n",
    "    'UNSW-NB15_4.csv'\n",
    "]\n",
    "features_file = 'NUSW-NB15_features.csv'\n",
    "\n",
    "# 2. Run Processing using CONFIG\n",
    "if os.path.exists(features_file):\n",
    "    # Passing CONFIG['snapshot_size'] (which is 2048)\n",
    "    all_snapshots, input_dim = process_data_incrementally(\n",
    "        data_files, \n",
    "        features_file, \n",
    "        snapshot_size=CONFIG['snapshot_size']\n",
    "    )\n",
    "    print(f\"Final Dataset Ready: {len(all_snapshots)} snapshots.\")\n",
    "else:\n",
    "    print(f\"Features file '{features_file}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec781dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BLOCK 4: DIGNN MODEL ARCHITECTURE ---\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv, GCN2Conv\n",
    "\n",
    "class IGNN_GRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Integrated GNN Cell (Section 3.5 of Paper).\n",
    "    Replaces standard GRU linear gates with GCNII convolutions.\n",
    "    Handles variable-sized graphs by using graph-level pooling of hidden states.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, layer=1):\n",
    "        super().__init__()\n",
    "        # GCNII Layers for Reset(r), Update(z), Candidate(h)\n",
    "        self.gcn_r = GCN2Conv(out_ch, alpha=0.1, theta=0.5, layer=layer+1)\n",
    "        self.gcn_z = GCN2Conv(out_ch, alpha=0.1, theta=0.5, layer=layer+1)\n",
    "        self.gcn_h = GCN2Conv(out_ch, alpha=0.1, theta=0.5, layer=layer+1)\n",
    "        \n",
    "        # Projection layer\n",
    "        self.lin_x = nn.Linear(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x, h_prev, edge_index):\n",
    "        # x: [num_nodes, hid_dim]\n",
    "        # h_prev: [hid_dim] or [1, hid_dim] - pooled hidden state from previous timestep\n",
    "        # edge_index: graph connectivity\n",
    "        \n",
    "        x_h = self.lin_x(x)\n",
    "        x_0 = x_h\n",
    "        \n",
    "        # Ensure h_prev is [num_nodes, hid_dim] by repeating if needed\n",
    "        if h_prev.dim() == 1:\n",
    "            h_prev = h_prev.unsqueeze(0)  # [hid_dim] -> [1, hid_dim]\n",
    "        \n",
    "        if h_prev.size(0) != x_h.size(0):\n",
    "            # Repeat h_prev to match number of nodes\n",
    "            h_prev = h_prev.expand(x_h.size(0), -1)\n",
    "        \n",
    "        # GCN gates\n",
    "        r = torch.sigmoid(self.gcn_r(x_h, x_0, edge_index) + self.gcn_r(h_prev, x_0, edge_index))\n",
    "        z = torch.sigmoid(self.gcn_z(x_h, x_0, edge_index) + self.gcn_z(h_prev, x_0, edge_index))\n",
    "        h_tilde = torch.tanh(self.gcn_h(x_h, x_0, edge_index) + self.gcn_h(r*h_prev, x_0, edge_index))\n",
    "        \n",
    "        # Update state\n",
    "        h_new = (1-z)*h_tilde + z*h_prev\n",
    "        \n",
    "        # Pool to graph level: average across all nodes\n",
    "        h_pooled = h_new.mean(dim=0)  # [num_nodes, hid_dim] -> [hid_dim]\n",
    "        \n",
    "        return h_new, h_pooled\n",
    "\n",
    "class DIGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Full DIGNN-A Architecture (Modified for Variable Graph Sizes):\n",
    "    Spatial (TransformerConv) -> Temporal (IG-NN with pooling) -> Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hid_dim, heads=2):\n",
    "        super().__init__()\n",
    "        # Spatial Module\n",
    "        self.spatial = TransformerConv(in_dim, hid_dim, heads=heads, concat=False)\n",
    "        \n",
    "        # Temporal Module\n",
    "        self.temporal = IGNN_GRU(hid_dim, hid_dim)\n",
    "        \n",
    "        # Classifier\n",
    "        self.clf = nn.Linear(hid_dim, 2)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        # seq: List of Data objects (sliding window)\n",
    "        h = None\n",
    "        \n",
    "        for data in seq:\n",
    "            x, ei = data.x, data.edge_index\n",
    "            \n",
    "            # Spatial processing\n",
    "            x_s = F.elu(self.spatial(x, ei))\n",
    "            \n",
    "            # Initialize hidden state if first step\n",
    "            if h is None:\n",
    "                h = torch.zeros(x_s.size(1), device=x_s.device)\n",
    "            \n",
    "            # Temporal evolution - returns (per_node_state, pooled_state)\n",
    "            _, h = self.temporal(x_s, h, ei)\n",
    "        \n",
    "        # Final classification on pooled state\n",
    "        logits = self.clf(h)  # [hid_dim] -> [2]\n",
    "        return F.log_softmax(logits, dim=0)\n",
    "\n",
    "# --- USAGE LINES ---\n",
    "# model = DIGNN(in_dim=100, hid_dim=CONFIG['hidden_dim'], heads=CONFIG['heads'])\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a954d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING PIPELINE ---\n",
      "Step 1: Parsing Feature Headers from NUSW-NB15_features.csv...\n",
      "\n",
      "Processing UNSW-NB15_1.csv...\n",
      "  Fitting Scaler on first file...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 342\n",
      "\n",
      "Processing UNSW-NB15_2.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 684\n",
      "\n",
      "Processing UNSW-NB15_3.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 1026\n",
      "\n",
      "Processing UNSW-NB15_4.csv...\n",
      "  Generating snapshots (Size: 2048)...\n",
      "  Done. Total snapshots so far: 1241\n",
      "\n",
      "Dataset Ready. Total Snapshots: 1241\n",
      "Train Size: 992 | Test Size: 249\n",
      "\n",
      "--- TRAINING (50 Epochs) ---\n",
      "Epoch 1/50 | Loss: 0.1235 | Time: 157.4s\n",
      "Epoch 2/50 | Loss: 0.1193 | Time: 168.2s\n",
      "Epoch 3/50 | Loss: 0.1180 | Time: 165.8s\n",
      "Epoch 4/50 | Loss: 0.1160 | Time: 179.1s\n",
      "Epoch 5/50 | Loss: 0.1127 | Time: 160.9s\n",
      "Epoch 6/50 | Loss: 0.1156 | Time: 176.6s\n",
      "Epoch 7/50 | Loss: 0.1135 | Time: 166.2s\n",
      "Epoch 8/50 | Loss: 0.1143 | Time: 166.8s\n",
      "Epoch 9/50 | Loss: 0.1140 | Time: 160.1s\n",
      "Epoch 10/50 | Loss: 0.1137 | Time: 185.7s\n",
      "Epoch 11/50 | Loss: 0.1129 | Time: 159.8s\n",
      "Epoch 12/50 | Loss: 0.1117 | Time: 169.0s\n",
      "Epoch 13/50 | Loss: 0.1118 | Time: 895.6s\n",
      "Epoch 14/50 | Loss: 0.1114 | Time: 150.7s\n",
      "Epoch 15/50 | Loss: 0.1132 | Time: 152.3s\n",
      "Epoch 16/50 | Loss: 0.1108 | Time: 152.2s\n",
      "Epoch 17/50 | Loss: 0.1097 | Time: 165.9s\n",
      "Epoch 18/50 | Loss: 0.1099 | Time: 285.2s\n",
      "Epoch 19/50 | Loss: 0.1087 | Time: 147.6s\n",
      "Epoch 20/50 | Loss: 0.1074 | Time: 301.2s\n",
      "Epoch 21/50 | Loss: 0.1063 | Time: 247.5s\n",
      "Epoch 22/50 | Loss: 0.1050 | Time: 161.5s\n",
      "Epoch 23/50 | Loss: 0.1029 | Time: 499.7s\n",
      "Epoch 24/50 | Loss: 0.0986 | Time: 1178.8s\n",
      "Epoch 25/50 | Loss: 0.0979 | Time: 147.5s\n",
      "Epoch 26/50 | Loss: 0.0977 | Time: 564.8s\n",
      "Epoch 27/50 | Loss: 0.0970 | Time: 252.4s\n",
      "Epoch 28/50 | Loss: 0.0977 | Time: 155.0s\n",
      "Epoch 29/50 | Loss: 0.0974 | Time: 152.4s\n",
      "Epoch 30/50 | Loss: 0.0979 | Time: 150.9s\n",
      "Epoch 31/50 | Loss: 0.0983 | Time: 151.9s\n",
      "Epoch 32/50 | Loss: 0.0977 | Time: 152.3s\n",
      "Epoch 33/50 | Loss: 0.1005 | Time: 152.1s\n",
      "Epoch 34/50 | Loss: 0.0982 | Time: 152.9s\n",
      "Epoch 35/50 | Loss: 0.0980 | Time: 153.2s\n",
      "Epoch 36/50 | Loss: 0.1554 | Time: 153.1s\n",
      "Epoch 37/50 | Loss: 0.1126 | Time: 156.6s\n",
      "Epoch 38/50 | Loss: 0.1135 | Time: 157.6s\n",
      "Epoch 39/50 | Loss: 0.1161 | Time: 158.5s\n",
      "Epoch 40/50 | Loss: 0.1099 | Time: 158.8s\n",
      "Epoch 41/50 | Loss: 0.1106 | Time: 1263.2s\n",
      "Epoch 42/50 | Loss: 0.1084 | Time: 214.4s\n",
      "Epoch 43/50 | Loss: 0.1076 | Time: 147.6s\n",
      "Epoch 44/50 | Loss: 0.1051 | Time: 149.5s\n",
      "Epoch 45/50 | Loss: 0.1033 | Time: 151.2s\n",
      "Epoch 46/50 | Loss: 0.1035 | Time: 155.7s\n",
      "Epoch 47/50 | Loss: 0.1063 | Time: 153.2s\n",
      "Epoch 48/50 | Loss: 0.1075 | Time: 153.5s\n",
      "Epoch 49/50 | Loss: 0.1054 | Time: 152.0s\n",
      "Epoch 50/50 | Loss: 0.1025 | Time: 152.8s\n",
      "Model Saved.\n",
      "\n",
      "--- EVALUATION ---\n",
      "Test Accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "# --- BLOCK 5: MAIN EXECUTION ---\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 1. DEFINE FILES (Update these to your exact paths)\n",
    "data_files = [\n",
    "    'UNSW-NB15_1.csv',\n",
    "    'UNSW-NB15_2.csv',\n",
    "    'UNSW-NB15_3.csv',\n",
    "    'UNSW-NB15_4.csv'\n",
    "]\n",
    "features_file = 'NUSW-NB15_features.csv'\n",
    "\n",
    "# 2. CHECK & RUN PROCESSING\n",
    "if os.path.exists(features_file):\n",
    "    print(\"--- STARTING PIPELINE ---\")\n",
    "    \n",
    "    # Call Block 2 Function (which calls Block 3)\n",
    "    # Uses CONFIG['snapshot_size'] = 2048\n",
    "    all_snapshots, input_dim = process_data_incrementally(\n",
    "        data_files, \n",
    "        features_file, \n",
    "        snapshot_size=CONFIG['snapshot_size']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset Ready. Total Snapshots: {len(all_snapshots)}\")\n",
    "    \n",
    "    # 3. SPLIT TRAIN/TEST (Time-based 80/20)\n",
    "    split_idx = int(len(all_snapshots) * 0.8)\n",
    "    train_snapshots = all_snapshots[:split_idx]\n",
    "    test_snapshots = all_snapshots[split_idx:]\n",
    "    \n",
    "    print(f\"Train Size: {len(train_snapshots)} | Test Size: {len(test_snapshots)}\")\n",
    "    \n",
    "    # 4. TRAINING LOOP\n",
    "    if len(train_snapshots) > CONFIG['window_size']:\n",
    "        print(f\"\\n--- TRAINING ({CONFIG['epochs']} Epochs) ---\")\n",
    "        \n",
    "        # Initialize Model (Block 4)\n",
    "        model = DIGNN(in_dim=input_dim, hid_dim=CONFIG['hidden_dim'], heads=CONFIG['heads']).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "        criterion = nn.NLLLoss()  # Use NLLLoss since output is log_softmax\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for ep in range(CONFIG['epochs']):\n",
    "            total_loss = 0\n",
    "            steps = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Sliding Window Loop\n",
    "            # We slide over the list of snapshots: [0..9] -> predict 9, [1..10] -> predict 10...\n",
    "            for i in range(len(train_snapshots) - CONFIG['window_size']):\n",
    "                # Get Sequence\n",
    "                sequence = train_snapshots[i : i+CONFIG['window_size']]\n",
    "                \n",
    "                # Move to Device\n",
    "                seq_gpu = [d.to(device) for d in sequence]\n",
    "                \n",
    "                # Target is the MAJORITY label of the last snapshot (graph-level prediction)\n",
    "                y_target = seq_gpu[-1].y\n",
    "                # Use majority class or mean label for graph-level target\n",
    "                graph_label = (y_target.float().mean() > 0.5).long()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(seq_gpu)  # Output shape: [2] (log probabilities for 2 classes)\n",
    "                \n",
    "                # Calculate Loss\n",
    "                loss = criterion(output.unsqueeze(0), graph_label.unsqueeze(0))  # Add batch dimension\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "            \n",
    "            avg_loss = total_loss / steps if steps > 0 else 0\n",
    "            print(f\"Epoch {ep+1}/{CONFIG['epochs']} | Loss: {avg_loss:.4f} | Time: {time.time()-start_time:.1f}s\")\n",
    "            \n",
    "        # Save Model\n",
    "        torch.save(model.state_dict(), 'dignn_nb15_complete.pth')\n",
    "        print(\"Model Saved.\")\n",
    "        \n",
    "        # 5. TESTING LOOP\n",
    "        print(\"\\n--- EVALUATION ---\")\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(len(test_snapshots) - CONFIG['window_size']):\n",
    "                sequence = test_snapshots[i : i+CONFIG['window_size']]\n",
    "                seq_gpu = [d.to(device) for d in sequence]\n",
    "                \n",
    "                # Graph-level target\n",
    "                y_target = seq_gpu[-1].y\n",
    "                graph_label = (y_target.float().mean() > 0.5).long()\n",
    "                \n",
    "                output = model(seq_gpu)  # Output shape: [2]\n",
    "                pred = output.argmax(dim=0)  # Get class with highest probability\n",
    "                \n",
    "                correct += (pred == graph_label).sum().item()\n",
    "                total_samples += 1\n",
    "                \n",
    "        acc = correct / total_samples if total_samples > 0 else 0\n",
    "        print(f\"Test Accuracy: {acc:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: Not enough data for the specified window size.\")\n",
    "else:\n",
    "    print(f\"Error: Features file '{features_file}' not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
